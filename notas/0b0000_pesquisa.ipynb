{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-begin",
   "metadata": {},
   "source": [
    "páginas:\n",
    "\n",
    "+ [Introducing completely free datasets for data-driven deep reinforcement learning | by Takuma Seno](https://towardsdatascience.com/introducing-completely-free-datasets-for-data-driven-deep-reinforcement-learning-a51e9bed85f9)\n",
    "+ [Offline RL learning by reducing Bootstrapping Error Reduction](https://www.programmersought.com/article/46775792348/)\n",
    "+ [BEAR (Bootstrapping Error Accumulation Reduction)](https://vitalab.github.io/article/2020/05/01/BEAR.html)\n",
    "+ [Offline Reinforcement Learning: How Conservative Algorithms Can Enable New Applications](https://bair.berkeley.edu/blog/2020/12/07/offline/)\n",
    "+ [Data-Driven Deep Reinforcement Learning – The Berkeley Artificial Intelligence Research Blog](https://bair.berkeley.edu/blog/2019/12/05/bear/)\n",
    "- - -\n",
    "+ [Offline (Batch) Reinforcement Learning: A Review of Literature and Applications](https://danieltakeshi.github.io/2020/06/28/offline-rl/)\n",
    "+ [Google AI Blog: Tackling Open Challenges in Offline Reinforcement Learning](https://ai.googleblog.com/2020/08/tackling-open-challenges-in-offline.html)\n",
    "- - -\n",
    "+ [An Introduction to Reinforcement Learning Q-Learning with Decision Trees by Chakrit Yau](https://towardsdatascience.com/reinforcement-learning-q-learning-with-decision-trees-ecb1215d9131)\n",
    "\n",
    "artigos:\n",
    "\n",
    "+ [[2005.01643] Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643)\n",
    "+ [[2004.07219] D4RL: Datasets for Deep Data-Driven Reinforcement Learning](https://arxiv.org/abs/2004.07219)\n",
    "+ [[1906.00949] Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction](https://arxiv.org/abs/1906.00949)\n",
    "- - -\n",
    "+ [[2006.03647] Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization](https://arxiv.org/abs/2006.03647)\n",
    "+ [[2005.05951] MOReL : Model-Based Offline Reinforcement Learning](https://arxiv.org/abs/2005.05951)\n",
    "- - -\n",
    "+ [PRELIMINARY VERSION DO NOT CITE - AAAI-9385.XiaoT.pdf](https://www.aaai.org/AAAI21Papers/AAAI-9385.XiaoT.pdf)\n",
    "\n",
    "libs:\n",
    "\n",
    "+ [d3rlpy: An offline reinforcement learning library](https://takuseno.github.io/d3rlpy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-equivalent",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
