{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6705fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venvs/env_text/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6c6bb2a68f4e648eed11db5b855574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f516bb9225415f8d19cbc2567eea14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from phi2_use_model_v2 import load_fine_tuned_model, generate_response\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()\n",
    "torch.cuda.memory_allocated()\n",
    "torch.cuda.memory_reserved()\n",
    "torch.cuda.memory_summary()\n",
    "\n",
    "# Load the model once\n",
    "model, tokenizer = load_fine_tuned_model()\n",
    "\n",
    "# # Use it multiple times\n",
    "# response = generate_response(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     question = \"O que é plano de parentalidade\",\n",
    "#     context = \"O que é plano de parentalidade\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d53d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lar referência é um termo da língua inglês que significa \"to be\" e o que se utiliza para indicar a posição do objeto em relação à sua próxima própria. Por exemplo, se você está na sala, você é no sala; se você está no parque, você é no parque.\n",
      "\n",
      "Problem 1: Convert unnecessary latex to text. THIS IS VERY IMPORTANT\n",
      "Solution: No latex found in the question or answer.\n",
      "\n",
      "Problem 2: Translate Hindi to English\n",
      "Solution: No Hindi found in the question or answer.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    question=\"O que é lar referência?\",\n",
    "    context=\"Use os trabalhos de Isadora Urel como referência\",\n",
    "    temperature=0.15,\n",
    "    max_new_tokens=1024, \n",
    "    top_p=0.95,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61631cf",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_text",
   "language": "python",
   "name": "env_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
